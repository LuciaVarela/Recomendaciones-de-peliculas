{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga completada.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL directa al archivo u.data\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
    "\n",
    "# Nombre local del archivo descargado\n",
    "file_name = 'u.data' \n",
    "\n",
    "# Descargar el archivo\n",
    "response = requests.get(url)\n",
    "with open(file_name, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print('Descarga completada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos usando pandas\n",
    "ratings_data = pd.read_csv(file_name, sep='\\t', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Mostrar las primeras filas de los datos\n",
    "print(ratings_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga de u.item completada.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# URL directa al archivo u.item\n",
    "url_item = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.item'\n",
    "\n",
    "# Nombre local del archivo descargado\n",
    "file_name_item = 'u.item'\n",
    "\n",
    "# Descargar el archivo\n",
    "response_item = requests.get(url_item)\n",
    "with open(file_name_item, 'wb') as f_item:\n",
    "    f_item.write(response_item.content)\n",
    "\n",
    "print('Descarga de u.item completada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos usando pandas\n",
    "ratings_data = pd.read_csv(file_name, sep='\\t', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Mostrar las primeras filas de los datos\n",
    "print(ratings_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de movies_data: 1682\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de películas\n",
    "movies_data = pd.read_csv(file_name_item, sep='|', encoding='latin-1', usecols=range(5),\n",
    "                          names=['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'])\n",
    "print(\"Tamaño de movies_data:\", len(movies_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos fusionado: 100000\n"
     ]
    }
   ],
   "source": [
    "# Fusionar los datos de ratings y películas\n",
    "merged_data = pd.merge(ratings_data, movies_data, on='movie_id')\n",
    "print(\"Tamaño del conjunto de datos fusionado:\", len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                       title  \\\n",
      "0      196       242       3  881250949                Kolya (1996)   \n",
      "1      186       302       3  891717742    L.A. Confidential (1997)   \n",
      "2       22       377       1  878887116         Heavyweights (1994)   \n",
      "3      244        51       2  880606923  Legends of the Fall (1994)   \n",
      "4      166       346       1  886397596         Jackie Brown (1997)   \n",
      "\n",
      "  release_date  video_release_date  \\\n",
      "0  24-Jan-1997                 NaN   \n",
      "1  01-Jan-1997                 NaN   \n",
      "2  01-Jan-1994                 NaN   \n",
      "3  01-Jan-1994                 NaN   \n",
      "4  01-Jan-1997                 NaN   \n",
      "\n",
      "                                            imdb_url  \n",
      "0    http://us.imdb.com/M/title-exact?Kolya%20(1996)  \n",
      "1  http://us.imdb.com/M/title-exact?L%2EA%2E+Conf...  \n",
      "2  http://us.imdb.com/M/title-exact?Heavyweights%...  \n",
      "3  http://us.imdb.com/M/title-exact?Legends%20of%...  \n",
      "4  http://us.imdb.com/M/title-exact?imdb-title-11...  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe resultante\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de merged_data después de eliminar duplicados: 100000\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "print(\"Tamaño de merged_data después de eliminar duplicados:\", len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "user_id                    0\n",
      "movie_id                   0\n",
      "rating                     0\n",
      "timestamp                  0\n",
      "title                      0\n",
      "release_date               9\n",
      "video_release_date    100000\n",
      "imdb_url                  13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Manejo de valores faltantes\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de merged_data después de la imputación de valores faltantes: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/6s1q_b2x7rldv60cty2jvx440000gn/T/ipykernel_17059/3832036702.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['rating'].fillna(merged_data['rating'].mean(), inplace=True)\n",
      "/var/folders/7r/6s1q_b2x7rldv60cty2jvx440000gn/T/ipykernel_17059/3832036702.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['release_date'].fillna('Unknown', inplace=True)\n",
      "/var/folders/7r/6s1q_b2x7rldv60cty2jvx440000gn/T/ipykernel_17059/3832036702.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['video_release_date'].fillna('Unknown', inplace=True)\n",
      "/var/folders/7r/6s1q_b2x7rldv60cty2jvx440000gn/T/ipykernel_17059/3832036702.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_data['video_release_date'].fillna('Unknown', inplace=True)\n",
      "/var/folders/7r/6s1q_b2x7rldv60cty2jvx440000gn/T/ipykernel_17059/3832036702.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['imdb_url'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Imputación de valores faltantes\n",
    "merged_data['rating'].fillna(merged_data['rating'].mean(), inplace=True)\n",
    "merged_data['release_date'].fillna('Unknown', inplace=True)\n",
    "merged_data['video_release_date'].fillna('Unknown', inplace=True)\n",
    "merged_data['imdb_url'].fillna('Unknown', inplace=True)\n",
    "print(\"Tamaño de merged_data después de la imputación de valores faltantes:\", len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el tipo de datos de timestamp a datetime\n",
    "merged_data['timestamp'] = pd.to_datetime(merged_data['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna separada para el año de lanzamiento de la película\n",
    "merged_data['release_year'] = pd.to_datetime(merged_data['release_date'], format='%d-%b-%Y', errors='coerce').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejar los valores \"Unknown\" en la columna 'release_year'\n",
    "merged_data.loc[merged_data['release_date'] == 'Unknown', 'release_year'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% - 20%)\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación (80% - 20%)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 64000\n",
      "Tamaño del conjunto de validación: 16000\n",
      "Tamaño del conjunto de prueba: 20000\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el tamaño de cada conjunto de datos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_data))\n",
    "print(\"Tamaño del conjunto de validación:\", len(val_data))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: surprise in /Users/luciavarelag/miniconda3/lib/python3.11/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /Users/luciavarelag/miniconda3/lib/python3.11/site-packages (from surprise) (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/luciavarelag/miniconda3/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/luciavarelag/miniconda3/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/luciavarelag/miniconda3/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.11.4)\n",
      "\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/luciavarelag/miniconda3/lib/python3.11/site-packages/fiona-1.9.6.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de ratings en el formato adecuado para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(merged_data[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = Dataset.load_from_df(train_data[['user_id', 'movie_id', 'rating']], reader).build_full_trainset()\n",
    "valset = Dataset.load_from_df(val_data[['user_id', 'movie_id', 'rating']], reader).build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperparámetros y sus rangos para la búsqueda de cuadrícula\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30, 40, 50],\n",
    "    'sim_options': {\n",
    "        'name': ['pearson_baseline', 'cosine'],\n",
    "        'min_support': [1, 5],\n",
    "        'user_based': [False]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una función para generar el modelo de filtrado colaborativo basado en elementos\n",
    "def create_model(k, sim_options):\n",
    "    return KNNBasic(k=k, sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Realizar la búsqueda de cuadrícula con validación cruzada k-fold\n",
    "grid_search = GridSearchCV(create_model, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'k': 40, 'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "Mejor puntaje RMSE: 0.9935510457734733\n",
      "Mejor puntaje MAE: 0.780699294078457\n"
     ]
    }
   ],
   "source": [
    "# Obtener los mejores hiperparámetros y los mejores puntajes de RMSE y MAE\n",
    "print('Mejores hiperparámetros:', grid_search.best_params['rmse'])\n",
    "print('Mejor puntaje RMSE:', grid_search.best_score['rmse'])\n",
    "print('Mejor puntaje MAE:', grid_search.best_score['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x116ba9550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = grid_search.best_estimator['rmse']\n",
    "best_model.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5271\n",
      "MAE:  0.4126\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "predictions = best_model.test(valset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las predicciones a una escala de 1 a 5 para calcular la precisión y el recall\n",
    "threshold = 3.5  # Umbral para considerar una predicción como positiva\n",
    "y_true = [int(true_r >= threshold) for (_, _, true_r) in valset]\n",
    "y_pred = [int(est >= threshold) for (_, _, _, est, _) in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de evaluación en el conjunto de validación:\n",
      "RMSE: 0.5271153881249381\n",
      "MAE: 0.41262884857566906\n",
      "Precisión: 0.8963249112549593\n",
      "Recall: 0.9638486583585943\n"
     ]
    }
   ],
   "source": [
    "print('Métricas de evaluación en el conjunto de validación:')\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print('Precisión:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de prueba\n",
    "testset = Dataset.load_from_df(test_data[['user_id', 'movie_id', 'rating']], reader).build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5325\n",
      "MAE:  0.4183\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "predictions_test = best_model.test(testset)\n",
    "rmse_test = accuracy.rmse(predictions_test)\n",
    "mae_test = accuracy.mae(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las predicciones de prueba a una escala de 1 a 5 para calcular la precisión y el recall\n",
    "y_true_test = [int(true_r >= threshold) for (_, _, true_r) in testset]\n",
    "y_pred_test = [int(est >= threshold) for (_, _, _, est, _) in predictions_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de evaluación en el conjunto de prueba:\n",
      "RMSE: 0.5325356791722661\n",
      "MAE: 0.4183391692032812\n",
      "Precisión: 0.888730145390369\n",
      "Recall: 0.9622383985441311\n"
     ]
    }
   ],
   "source": [
    "print('Métricas de evaluación en el conjunto de prueba:')\n",
    "print('RMSE:', rmse_test)\n",
    "print('MAE:', mae_test)\n",
    "print('Precisión:', precision_test)\n",
    "print('Recall:', recall_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener las top n recomendaciones para un usuario\n",
    "def get_top_n_recommendations(user_id, n=10):\n",
    "    # Obtener las películas no vistas por el usuario\n",
    "    movies_unseen = movies_data[~movies_data['movie_id'].isin(ratings_data[ratings_data['user_id'] == user_id]['movie_id'])]\n",
    "    \n",
    "    # Preparar lista de predicciones para las películas no vistas\n",
    "    recommendations = []\n",
    "    for movie_id in movies_unseen['movie_id']:\n",
    "        prediction = best_model.predict(user_id, movie_id)\n",
    "        recommendations.append((prediction.est, movie_id))\n",
    "    \n",
    "    # Ordenar recomendaciones por rating estimado\n",
    "    recommendations.sort(reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    # Obtener los títulos de las películas recomendadas\n",
    "    recommended_movies = [movies_data[movies_data['movie_id'] == movie_id]['title'].values[0] for (_, movie_id) in recommendations[:n]]\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recomendaciones para el usuario 4:\n",
      "1. Three Colors: Red (1994)\n",
      "2. Blood For Dracula (Andy Warhol's Dracula) (1974)\n",
      "3. Crooklyn (1994)\n",
      "4. Diva (1981)\n",
      "5. Hearts and Minds (1996)\n",
      "6. Two Bits (1995)\n",
      "7. Hear My Song (1991)\n",
      "8. 8 1/2 (1963)\n",
      "9. Lassie (1994)\n",
      "10. Homeward Bound II: Lost in San Francisco (1996)\n"
     ]
    }
   ],
   "source": [
    "# Solicitar al usuario que ingrese el user_id\n",
    "user_id = int(input(\"Ingrese el user_id para obtener recomendaciones: \"))\n",
    "\n",
    "# Obtener y mostrar las top 10 recomendaciones para el usuario ingresado\n",
    "top_recommendations = get_top_n_recommendations(user_id)\n",
    "print(f\"\\nTop 10 recomendaciones para el usuario {user_id}:\")\n",
    "for idx, movie_title in enumerate(top_recommendations, start=1):\n",
    "    print(f\"{idx}. {movie_title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
